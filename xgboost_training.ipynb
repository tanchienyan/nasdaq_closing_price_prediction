{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5237892, 17)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet('train.parquet')\n",
    "train = train[~train['target'].isna()]\n",
    "print(train.shape)\n",
    "size_col = ['imbalance_size','matched_size','bid_size','ask_size']\n",
    "\n",
    "# Normalize Volume Features for each Stock by dividing by median\n",
    "for _ in size_col:\n",
    "    train[f\"scale_{_}\"] = train[_] / train.groupby(['stock_id'])[_].transform('median')\n",
    "    \n",
    "# buy-side imbalance; 1\n",
    "# sell-side imbalance; -1\n",
    "# no imbalance; 0\n",
    "train['auc_bid_size'] = train['matched_size']\n",
    "train['auc_ask_size'] = train['matched_size']\n",
    "train.loc[train['imbalance_buy_sell_flag']==1,'auc_bid_size'] += train.loc[train['imbalance_buy_sell_flag']==1,'imbalance_size']\n",
    "train.loc[train['imbalance_buy_sell_flag']==-1,'auc_ask_size'] += train.loc[train['imbalance_buy_sell_flag']==-1,'imbalance_size']\n",
    "# Gives a better signal of true market pressure (excess demand or supply).\n",
    "# This is especially useful in an auction setting where imbalance can signal future price direction.\n",
    "\n",
    "weight_df = pd.DataFrame()\n",
    "weight_df['stock_id'] = list(range(200))\n",
    "weight_df['weight'] =  [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "\n",
    "train = train.merge(weight_df,how='left',on=['stock_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>...</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>scale_imbalance_size</th>\n",
       "      <th>scale_matched_size</th>\n",
       "      <th>scale_bid_size</th>\n",
       "      <th>scale_ask_size</th>\n",
       "      <th>auc_bid_size</th>\n",
       "      <th>auc_ask_size</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "      <td>1.547844</td>\n",
       "      <td>0.635182</td>\n",
       "      <td>3.001806</td>\n",
       "      <td>0.376896</td>\n",
       "      <td>16560879.33</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "      <td>1.031025</td>\n",
       "      <td>0.593159</td>\n",
       "      <td>0.261912</td>\n",
       "      <td>1.560460</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1808818.16</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "      <td>0.945033</td>\n",
       "      <td>0.457058</td>\n",
       "      <td>3.063661</td>\n",
       "      <td>1.372570</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>2122247.90</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "      <td>2.187799</td>\n",
       "      <td>0.308522</td>\n",
       "      <td>0.114156</td>\n",
       "      <td>22.488728</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>30307427.89</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.790134</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.025198</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>18308164.91</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237887</th>\n",
       "      <td>195</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>2440722.89</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>28280361.74</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>...</td>\n",
       "      <td>2.310276</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_195</td>\n",
       "      <td>1.033448</td>\n",
       "      <td>1.177623</td>\n",
       "      <td>1.259572</td>\n",
       "      <td>12.147279</td>\n",
       "      <td>28280361.74</td>\n",
       "      <td>30721084.63</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237888</th>\n",
       "      <td>196</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>349510.47</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>9187699.11</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.220077</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_196</td>\n",
       "      <td>0.692713</td>\n",
       "      <td>1.753503</td>\n",
       "      <td>9.938564</td>\n",
       "      <td>4.276373</td>\n",
       "      <td>9187699.11</td>\n",
       "      <td>9537209.58</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237889</th>\n",
       "      <td>197</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>12725436.10</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>...</td>\n",
       "      <td>1.169443</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.324129</td>\n",
       "      <td>1.117586</td>\n",
       "      <td>11.965859</td>\n",
       "      <td>12725436.10</td>\n",
       "      <td>12725436.10</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237890</th>\n",
       "      <td>198</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1000898.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>94773271.05</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.540184</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_198</td>\n",
       "      <td>0.132882</td>\n",
       "      <td>1.117509</td>\n",
       "      <td>0.828980</td>\n",
       "      <td>4.372968</td>\n",
       "      <td>95774169.89</td>\n",
       "      <td>94773271.05</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237891</th>\n",
       "      <td>199</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1884285.71</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>24073677.32</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.530285</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_199</td>\n",
       "      <td>1.430339</td>\n",
       "      <td>1.523099</td>\n",
       "      <td>4.448923</td>\n",
       "      <td>5.182861</td>\n",
       "      <td>24073677.32</td>\n",
       "      <td>25957963.03</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5237892 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0               0        0                  0      3180602.69   \n",
       "1               1        0                  0       166603.91   \n",
       "2               2        0                  0       302879.87   \n",
       "3               3        0                  0     11917682.27   \n",
       "4               4        0                  0       447549.96   \n",
       "...           ...      ...                ...             ...   \n",
       "5237887       195      480                540      2440722.89   \n",
       "5237888       196      480                540       349510.47   \n",
       "5237889       197      480                540            0.00   \n",
       "5237890       198      480                540      1000898.84   \n",
       "5237891       199      480                540      1884285.71   \n",
       "\n",
       "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                              1         0.999812   13380276.64        NaN   \n",
       "1                             -1         0.999896    1642214.25        NaN   \n",
       "2                             -1         0.999561    1819368.03        NaN   \n",
       "3                             -1         1.000171   18389745.62        NaN   \n",
       "4                             -1         0.999532   17860614.95        NaN   \n",
       "...                          ...              ...           ...        ...   \n",
       "5237887                       -1         1.000317   28280361.74   0.999734   \n",
       "5237888                       -1         1.000643    9187699.11   1.000129   \n",
       "5237889                        0         0.995789   12725436.10   0.995789   \n",
       "5237890                        1         0.999210   94773271.05   0.999210   \n",
       "5237891                       -1         1.002129   24073677.32   1.000859   \n",
       "\n",
       "         near_price  bid_price  ...    target  time_id       row_id  \\\n",
       "0               NaN   0.999812  ... -3.029704        0        0_0_0   \n",
       "1               NaN   0.999896  ... -5.519986        0        0_0_1   \n",
       "2               NaN   0.999403  ... -8.389950        0        0_0_2   \n",
       "3               NaN   0.999999  ... -4.010200        0        0_0_3   \n",
       "4               NaN   0.999394  ... -7.349849        0        0_0_4   \n",
       "...             ...        ...  ...       ...      ...          ...   \n",
       "5237887    0.999734   1.000317  ...  2.310276    26454  480_540_195   \n",
       "5237888    1.000386   1.000643  ... -8.220077    26454  480_540_196   \n",
       "5237889    0.995789   0.995789  ...  1.169443    26454  480_540_197   \n",
       "5237890    0.999210   0.998970  ... -1.540184    26454  480_540_198   \n",
       "5237891    1.001494   1.002129  ... -6.530285    26454  480_540_199   \n",
       "\n",
       "         scale_imbalance_size  scale_matched_size  scale_bid_size  \\\n",
       "0                    1.547844            0.635182        3.001806   \n",
       "1                    1.031025            0.593159        0.261912   \n",
       "2                    0.945033            0.457058        3.063661   \n",
       "3                    2.187799            0.308522        0.114156   \n",
       "4                    0.223200            0.790134        0.982033   \n",
       "...                       ...                 ...             ...   \n",
       "5237887              1.033448            1.177623        1.259572   \n",
       "5237888              0.692713            1.753503        9.938564   \n",
       "5237889              0.000000            1.324129        1.117586   \n",
       "5237890              0.132882            1.117509        0.828980   \n",
       "5237891              1.430339            1.523099        4.448923   \n",
       "\n",
       "        scale_ask_size  auc_bid_size  auc_ask_size  weight  \n",
       "0             0.376896   16560879.33   13380276.64   0.004  \n",
       "1             1.560460    1642214.25    1808818.16   0.001  \n",
       "2             1.372570    1819368.03    2122247.90   0.002  \n",
       "3            22.488728   18389745.62   30307427.89   0.006  \n",
       "4             0.025198   17860614.95   18308164.91   0.004  \n",
       "...                ...           ...           ...     ...  \n",
       "5237887      12.147279   28280361.74   30721084.63   0.004  \n",
       "5237888       4.276373    9187699.11    9537209.58   0.001  \n",
       "5237889      11.965859   12725436.10   12725436.10   0.004  \n",
       "5237890       4.372968   95774169.89   94773271.05   0.006  \n",
       "5237891       5.182861   24073677.32   25957963.03   0.004  \n",
       "\n",
       "[5237892 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['date_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_no_hist_polars(df):\n",
    "    # Add feature for ask_size - bid_size and then apply rolling calculations\n",
    "    df = pl.from_pandas(df)\n",
    "    feas_list = ['stock_id','seconds_in_bucket','imbalance_size','imbalance_buy_sell_flag',\n",
    "               'reference_price','matched_size','far_price','near_price','bid_price','bid_size',\n",
    "                'ask_price','ask_size','wap','scale_imbalance_size','scale_matched_size','scale_bid_size','scale_ask_size'\n",
    "                 ,'auc_bid_size','auc_ask_size']\n",
    "    # Stage 1: Feature Engineering\n",
    "    df = df.with_columns([\n",
    "        # Notional Values, Auction Sizes, Liquidity and Spread, Imbalance Signals and Depth\n",
    "        # Depth measures how imbalanced the order sizes are relative to the auction’s potential crossing price range, giving a sense of market depth or the pressure that the net volume might exert on the closing auction price\n",
    "        (pl.col('ask_size') * pl.col('ask_price')).alias(\"ask_money\"),\n",
    "        (pl.col('bid_size') * pl.col('bid_price')).alias(\"bid_money\"),\n",
    "        (pl.col('ask_size') + pl.col(\"auc_ask_size\")).alias(\"ask_size_all\"),\n",
    "        (pl.col('bid_size') + pl.col(\"auc_bid_size\")).alias(\"bid_size_all\"),\n",
    "        (pl.col('ask_size') + pl.col(\"auc_ask_size\") + pl.col('bid_size') + pl.col(\"auc_bid_size\")).alias(\"volumn_size_all\"),\n",
    "        (pl.col('reference_price') * pl.col('auc_ask_size')).alias(\"ask_auc_money\"),\n",
    "        (pl.col('reference_price') * pl.col('auc_bid_size')).alias(\"bid_auc_money\"),\n",
    "        (pl.col('ask_size') * pl.col('ask_price') + pl.col('bid_size') * pl.col('bid_price')).alias(\"volumn_money\"),\n",
    "        (pl.col('ask_size') + pl.col('bid_size')).alias('volume_cont'),\n",
    "        (pl.col('ask_size') - pl.col('bid_size')).alias('diff_ask_bid_size'),\n",
    "        (pl.col('imbalance_size') + 2 * pl.col('matched_size')).alias('volumn_auc'),\n",
    "        ((pl.col('imbalance_size') + 2 * pl.col('matched_size')) * pl.col(\"reference_price\")).alias('volumn_auc_money'),\n",
    "        ((pl.col('ask_price') + pl.col('bid_price'))/2).alias('mid_price'),\n",
    "        ((pl.col('near_price') + pl.col('far_price'))/2).alias('mid_price_near_far'),\n",
    "        (pl.col('ask_price') - pl.col('bid_price')).alias('price_diff_ask_bid'),\n",
    "        (pl.col('ask_price') / pl.col('bid_price')).alias('price_div_ask_bid'),\n",
    "        (pl.col('imbalance_buy_sell_flag') * pl.col('scale_imbalance_size')).alias('flag_scale_imbalance_size'),\n",
    "        (pl.col('imbalance_buy_sell_flag') * pl.col('imbalance_size')).alias('flag_imbalance_size'),\n",
    "        (pl.col('imbalance_size') / pl.col('matched_size') * pl.col('imbalance_buy_sell_flag')).alias(\"div_flag_imbalance_size_2_balance\"),\n",
    "        ((pl.col('ask_price') - pl.col('bid_price')) * pl.col('imbalance_size')).alias('price_pressure'),\n",
    "        ((pl.col('ask_price') - pl.col('bid_price')) * pl.col('imbalance_size') * pl.col('imbalance_buy_sell_flag')).alias('price_pressure_v2'),\n",
    "        ((pl.col(\"ask_size\") - pl.col(\"bid_size\")) / (pl.col(\"far_price\") - pl.col(\"near_price\"))).alias(\"depth_pressure\"),\n",
    "        (pl.col(\"bid_size\") / pl.col(\"ask_size\")).alias(\"div_bid_size_ask_size\"),\n",
    "    ])\n",
    "    feas_list.extend(['ask_money', 'bid_money', 'ask_auc_money','bid_auc_money',\"ask_size_all\",\"bid_size_all\",\"volumn_size_all\",\n",
    "                      'volumn_money','volume_cont',\"volumn_auc\",\"volumn_auc_money\",\"mid_price\",\n",
    "                      'mid_price_near_far','price_diff_ask_bid',\"price_div_ask_bid\",\"flag_imbalance_size\",\"div_flag_imbalance_size_2_balance\",\n",
    "                     \"price_pressure\",\"price_pressure_v2\",\"depth_pressure\",\"flag_scale_imbalance_size\",\"diff_ask_bid_size\"])        \n",
    "\n",
    "    # Ratio Features: yields a slight improvement\n",
    "    add_cols = []\n",
    "    for col1, col2 in [\n",
    "        (\"imbalance_size\",\"bid_size\"),\n",
    "        (\"imbalance_size\",\"ask_size\"),\n",
    "        (\"matched_size\",\"bid_size\"),\n",
    "        (\"matched_size\",\"ask_size\"),\n",
    "        (\"imbalance_size\",\"volume_cont\"),\n",
    "        (\"matched_size\",\"volume_cont\"),\n",
    "        (\"auc_bid_size\",\"bid_size\"),\n",
    "        (\"auc_ask_size\",\"ask_size\"),\n",
    "        (\"bid_auc_money\",\"bid_money\"),\n",
    "        (\"ask_auc_money\",\"ask_money\"),\n",
    "    ]:\n",
    "        add_cols.append((pl.col(col1) / pl.col(col2)).alias(f\"div_{col1}_2_{col2}\"))\n",
    "        feas_list.append(f\"div_{col1}_2_{col2}\")        \n",
    "    df = df.with_columns(add_cols)\n",
    "\n",
    "    # Stage 2 Creates additional imbalance features by comparing pairs of columns: \n",
    "    # Capture the difference or imbalance between buy and sell sides\n",
    "    # Measures how skewed one side is vs. the other, producing values typically between -1 and +1\n",
    "    # Exclude price-related features\n",
    "    add_cols = []\n",
    "    for pair1,pair2 in [\n",
    "        ('ask_size','bid_size'),\n",
    "        ('ask_money','bid_money'),\n",
    "        ('volumn_money','volumn_auc_money'),\n",
    "        ('volume_cont','volumn_auc'),\n",
    "        ('imbalance_size','matched_size'),\n",
    "        ('auc_ask_size','auc_bid_size'),\n",
    "        (\"ask_size_all\",'bid_size_all')\n",
    "    ]:\n",
    "        col_imb = f\"imb1_{pair1}_{pair2}\"\n",
    "        add_cols.extend([\n",
    "            ((pl.col(pair1) - pl.col(pair2)) / (pl.col(pair1) + pl.col(pair2))).alias(col_imb),\n",
    "        ])\n",
    "        feas_list.extend([col_imb])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    # Price Imbalance\n",
    "    # Takes every pair of price columns, Computes price imbalance ratios\n",
    "    # Captures how different two price references are relative to their sum\n",
    "    fea_append_list = []\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\",\"mid_price\"]\n",
    "    for c in combinations(prices, 2):\n",
    "        fea_append_list.append(((pl.col(c[0]) - pl.col(c[1])) / (pl.col(c[0]) + pl.col(c[1]))).alias(f\"imb1_{c[0]}_{c[1]}\"))\n",
    "        # fea_append_list.append((pl.col(c[0]) - pl.col(c[1])).alias(f\"diff_{c[0]}_{c[1]}\"))\n",
    "        feas_list.extend([f\"imb1_{c[0]}_{c[1]}\"])\n",
    "    df = df.with_columns(fea_append_list)\n",
    "    \n",
    "    \n",
    "    # Market Urgency\n",
    "    df = df.with_columns([\n",
    "        ((pl.col(\"imb1_ask_size_bid_size\") + 2) * (pl.col(\"imb1_ask_price_bid_price\") + 2) * (pl.col(\"imb1_auc_ask_size_auc_bid_size\")+2)).alias(\"market_urgency_v2\"),\n",
    "        (pl.col('price_diff_ask_bid') * (pl.col('imb1_ask_size_bid_size'))).alias('market_urgency'),\n",
    "        (pl.col('imb1_ask_price_bid_price') * (pl.col('imb1_ask_size_bid_size'))).alias('market_urgency_v3'),\n",
    "    ])\n",
    "    feas_list.extend([f\"market_urgency_v3\",'market_urgency','market_urgency_v2'])\n",
    "    \n",
    "    feas_list = ['imb1_wap_mid_price', 'imb1_ask_money_bid_money', 'imb1_volume_cont_volumn_auc', 'imb1_reference_price_ask_price', \n",
    "                 'imb1_reference_price_mid_price', 'seconds_in_bucket', 'div_flag_imbalance_size_2_balance', 'ask_price', \n",
    "                 'imb1_reference_price_bid_price', 'scale_matched_size', 'imb1_near_price_wap', 'volumn_auc_money', 'imb1_far_price_wap', \n",
    "                 'bid_size', 'scale_bid_size', 'bid_size_all']\n",
    "    # Isolation of features\n",
    "    # Define base columns and window sizes\n",
    "    add_cols = []\n",
    "    for col in [\"bid_auc_money\",\"imb1_reference_price_wap\",\"bid_size_all\",\n",
    "                \"imb1_auc_ask_size_auc_bid_size\",\"div_flag_imbalance_size_2_balance\",\n",
    "                \"imb1_ask_size_all_bid_size_all\",\"flag_imbalance_size\",\"imb1_reference_price_mid_price\"]:\n",
    "        # Generate rolling features (mean + std)\n",
    "        for window in [3,6,18,36,60]:\n",
    "            add_cols.append(pl.col(col).rolling_mean(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_mean_{col}'))\n",
    "            add_cols.append(pl.col(col).rolling_std(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_std_{col}'))\n",
    "            feas_list.extend([f'rolling{window}_mean_{col}',f'rolling{window}_std_{col}'])\n",
    "    feas_list = ['imb1_wap_mid_price', 'imb1_ask_money_bid_money', 'imb1_volume_cont_volumn_auc', \n",
    "                     'imb1_reference_price_ask_price', 'imb1_reference_price_mid_price', \n",
    "                     'seconds_in_bucket', 'div_flag_imbalance_size_2_balance', 'ask_price', \n",
    "                     'imb1_reference_price_bid_price', 'scale_matched_size', 'imb1_near_price_wap', \n",
    "                     'volumn_auc_money', 'imb1_far_price_wap', 'bid_size', 'scale_bid_size', 'bid_size_all', \n",
    "                     'rolling18_mean_imb1_auc_ask_size_auc_bid_size', 'rolling3_mean_div_flag_imbalance_size_2_balance', \n",
    "                     'rolling60_std_div_flag_imbalance_size_2_balance', 'rolling36_mean_flag_imbalance_size', \n",
    "                     'rolling3_std_imb1_auc_ask_size_auc_bid_size', 'rolling18_mean_imb1_ask_size_all_bid_size_all', \n",
    "                     'rolling6_mean_div_flag_imbalance_size_2_balance', 'rolling6_std_imb1_auc_ask_size_auc_bid_size', \n",
    "                     'rolling3_mean_imb1_auc_ask_size_auc_bid_size', 'rolling60_std_imb1_auc_ask_size_auc_bid_size', \n",
    "                     'rolling6_std_bid_size_all', 'rolling3_std_bid_size_all', 'rolling3_mean_bid_size_all', \n",
    "                     'rolling18_std_bid_auc_money', 'rolling36_mean_bid_auc_money',\"rolling60_mean_imb1_reference_price_wap\",\n",
    "                    'rolling18_mean_imb1_reference_price_wap', 'rolling3_mean_imb1_reference_price_mid_price']\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "# Time-shifted (lag) features for temporal patterns\n",
    "  # for col in [\"flag_imbalance_size\", \"imb1_reference_price_wap\", \"imb1_reference_price_mid_price\",\"mid_price\", \"imb1_far_price_wap\", \n",
    "  #             \"matched_size\", \"reference_price\", \"imbalance_buy_sell_flag\"]:\n",
    "  #     add_cols = []\n",
    "  #     for window_size in [1,2,4,6,12]:\n",
    "              #Shift the column backwards (i.e., look at past values)\n",
    "  #           add_cols.append(pl.col(col).shift(window_size).over('stock_id','date_id').alias(f'shift{window_size}_{col}'))\n",
    "              # Ratio of current to past values\n",
    "  #           add_cols.append((pl.col(col) / pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'div_shift{window_size}_{col}'))\n",
    "              # Difference from past value\n",
    "  #           add_cols.append((pl.col(col) - pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'diff_shift{window_size}_{col}'))\n",
    "              # Add feature names to feature list\n",
    "  #           feas_list.extend([f'shift{window_size}_{col}',f'div_shift{window_size}_{col}',f'diff_shift{window_size}_{col}'])\n",
    "        # Add all created features to the dataframe\n",
    "  #     df = df.with_columns(add_cols)\n",
    "\n",
    "    # Miscellaneous\n",
    "    # Momentum and Spread Intensity\n",
    "    df = df.with_columns([\n",
    "        # Captures how quickly the auction-side pressure (buy vs sell imbalance) is shifting, indicating a possible change in market direction.\n",
    "        pl.col(\"flag_imbalance_size\").diff().over('stock_id','date_id').alias(\"imbalance_momentum_unscaled\"),\n",
    "        # Measures the rate of change in bid-ask spread, signaling rising or falling short-term market uncertainty or liquidity.\n",
    "        pl.col(\"price_diff_ask_bid\").diff().over('stock_id','date_id').alias(\"spread_intensity\"),\n",
    "    ])\n",
    "    feas_list.extend([\"imbalance_momentum_unscaled\",\"spread_intensity\"])\n",
    "    # Normalize Imbalance Momentum\n",
    "    # Normalizes change in imbalance sentiment by trade volume, giving a clearer picture of how significant the pressure shift is relative to market activity.\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"imbalance_momentum_unscaled\")/pl.col(\"matched_size\")).alias(\"imbalance_momentum\")\n",
    "    ])\n",
    "    feas_list.extend([\"imbalance_momentum\"])\n",
    "\n",
    "    # Calculate diff features for specific columns\n",
    "    # Computes time-based differences for each feature over rolling windows (e.g., 1, 2, 3, 10 steps back) within each stock-day group \n",
    "    # to capture short-term trends or volatility—helping detect momentum, reversals, or unusual market behavior.\n",
    "    add_cols = []\n",
    "    for col in ['ask_price',\n",
    " 'bid_price',\n",
    " 'imb1_reference_price_near_price',\n",
    " 'bid_size',\n",
    " 'scale_bid_size',\n",
    " 'mid_price',\n",
    " 'ask_size',\n",
    " 'price_div_ask_bid',\n",
    " 'div_bid_size_ask_size',\n",
    " 'market_urgency',\n",
    " 'wap',\n",
    " 'imbalance_momentum']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            add_cols.append((pl.col(col).diff(window).over('stock_id','date_id')).alias(f\"{col}_diff_{window}\"))\n",
    "            feas_list.append(f\"{col}_diff_{window}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    # Looping over mock_period\n",
    "    # Each number represents how many time steps ahead we want to simulate the target (i.e., forecasting wap a few steps into the future).\n",
    "    for mock_period in [1,3,12,6]:\n",
    "        # Computes the future WAP (weighted average price) mock_period steps ahead for each stock and day\n",
    "        df = df.with_columns([pl.col(\"wap\").shift(-mock_period).over(\"stock_id\",\"date_id\").alias(f\"wap_shift_n{mock_period}\")])\n",
    "        # Relative return or ratio between future WAP and current WAP; gives raw signal of price movement\n",
    "        df = df.with_columns([(pl.col(f\"wap_shift_n{mock_period}\")/pl.col(\"wap\")).alias(\"target_single\")])\n",
    "\n",
    "\n",
    "        tmp_df = df.select(pl.col(\"target_single\"),pl.col(\"weight\")).to_pandas()\n",
    "        # Cleaning NaN weights\n",
    "        tmp_df.loc[tmp_df[\"target_single\"].isna(),\"weight\"] = 0\n",
    "        # Reintroduces the adjusted weights back into the Polars DataFrame\n",
    "        df = df.with_columns([pl.lit(np.array(tmp_df[\"weight\"])).alias(\"weight_tmp\")])\n",
    "\n",
    "        # Weighted average of target_single across all stocks for the same timestamp (seconds_in_bucket) and day, creating a synthetic index return\n",
    "        df = df.with_columns([\n",
    "            (((pl.col(\"weight_tmp\") * pl.col(\"target_single\")).sum().over(\"date_id\",\"seconds_in_bucket\")) / ((pl.col(\"weight_tmp\")).sum().over(\"date_id\",\"seconds_in_bucket\"))).alias(\"index_target_mock\")])\n",
    "        \n",
    "        # Simulate the price movement relative to the market index\n",
    "        df = df.with_columns([((pl.col(\"target_single\") - pl.col(\"index_target_mock\"))*10000).alias(\"target_mock\")])\n",
    "\n",
    "        # Shifts the mock target backwards, aligning the prediction with the current timestep; for supervised learning\n",
    "        df = df.with_columns([pl.col(\"target_mock\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"target_mock_shift{mock_period}\")])\n",
    "            #pl.col(\"index_target_mock\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"index_target_mock_shift{mock_period}\")\n",
    "            #pl.col(\"target_single\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"target_single_shift{mock_period}\")\n",
    "        \n",
    "        # df.drop_in_place(\"wap_shift_6\")\n",
    "        # df.drop_in_place(\"target_single_shift6\")\n",
    "        # df.drop_in_place(\"indexwap_shift6\")\n",
    "        # add_cols_new = []\n",
    "\n",
    "    add_cols = []\n",
    "    # Computes rolling averages of lagged mock target values (predicted auction return) across various window sizes to capture short- and long-term trends for each stock on given day\n",
    "    for col in ['target_mock_shift6','target_mock_shift1','target_mock_shift3','target_mock_shift12']:\n",
    "        for window in [1, 3,6,12,24,48]:\n",
    "            add_cols.append(pl.col(col).rolling_mean(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_mean_{col}'))\n",
    "            #add_cols.append(pl.col(col).rolling_std(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_std_{col}'))\n",
    "            # add_cols_new.extend([f'rolling{window}_mean_{col}'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    # Appends only selected rolling target features to the list of features used in modeling\n",
    "    keep_cols_new = ['rolling48_mean_target_mock_shift3', 'rolling48_mean_target_mock_shift1', 'rolling48_mean_target_mock_shift12',\n",
    "                     'rolling1_mean_target_mock_shift6', 'rolling24_mean_target_mock_shift6','rolling24_mean_target_mock_shift12',]\n",
    "    feas_list.extend(keep_cols_new)\n",
    "    \n",
    "    # Captures how selected features change over time by computing shifted, relative, and absolute differences — helps detect trend reversals or momentum changes\n",
    "    add_cols = []\n",
    "    for col in [\"imb1_auc_ask_size_auc_bid_size\",\"flag_imbalance_size\",\"price_pressure_v2\",\"scale_matched_size\"]:\n",
    "        for window_size in [1,2,3,6,12]:\n",
    "            add_cols.append(pl.col(col).shift(window_size).over('stock_id','date_id').alias(f'shift{window_size}_{col}'))\n",
    "            add_cols.append((pl.col(col) / pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'div_shift{window_size}_{col}'))\n",
    "            add_cols.append((pl.col(col) - pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'diff_shift{window_size}_{col}'))\n",
    "            #feas_list.extend([f'shift{window_size}_{col}',f'div_shift{window_size}_{col}',f'diff_shift{window_size}_{col}'])\n",
    "            # shift3_price_pressure_v2: Value 3 time steps ago\n",
    "            # div_shift3_*: How many times current is over past value\n",
    "            # diff_shift3_*: Absolute change from 3 steps ago\n",
    "    feas_list.extend(['div_shift6_imb1_auc_ask_size_auc_bid_size',\n",
    " 'diff_shift6_price_pressure_v2',\n",
    " 'shift1_price_pressure_v2',\n",
    " 'div_shift3_flag_imbalance_size',\n",
    " 'div_shift12_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift3_scale_matched_size',\n",
    " 'diff_shift6_flag_imbalance_size',\n",
    " 'shift12_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift12_price_pressure_v2',\n",
    " 'shift6_flag_imbalance_size',\n",
    " 'diff_shift3_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift12_flag_imbalance_size',\n",
    " 'shift12_flag_imbalance_size'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    # Global features summarize weighted auction-level behavior, helping the model understand how a stock compares to the broader market context \n",
    "    # Useful for capturing relative sentiment and positioning\n",
    "    add_cols = []\n",
    "    for col in ['imb1_ask_price_mid_price',\n",
    " 'market_urgency',\n",
    " 'market_urgency_diff_1',\n",
    " 'imb1_ask_money_bid_money',\n",
    " 'rolling18_mean_imb1_ask_size_all_bid_size_all',\n",
    " 'rolling18_mean_imb1_auc_ask_size_auc_bid_size',\n",
    " 'rolling18_mean_imb1_reference_price_wap',\n",
    " 'ask_price_diff_3',\n",
    " 'diff_shift1_price_pressure_v2',\n",
    " 'diff_shift12_scale_matched_size',\n",
    " 'diff_shift1_flag_imbalance_size',\n",
    " 'imb1_ask_size_bid_size',\n",
    " 'imb1_bid_price_mid_price',\n",
    " 'rolling48_mean_target_mock_shift6']:\n",
    "        add_cols.append((((pl.col(col) * pl.col(\"weight\")).sum().over(\"date_id\",\"seconds_in_bucket\"))/(((pl.col(\"weight\")).sum().over(\"date_id\",\"seconds_in_bucket\")))).alias(f\"global_{col}\"))\n",
    "        feas_list.append(f\"global_{col}\")\n",
    "    # Tidying\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    \n",
    "    # MACD:  Moving Average Convergence Divergence\n",
    "    # Extract momentum-based features from key price signals (mid_price_near_far, imb1_reference_price_wap, near_price) \n",
    "    rsi_cols = [\"mid_price_near_far\",\"imb1_reference_price_wap\",\"near_price\",]\n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for window_size in [3,6,12,24,48]:\n",
    "            # Exponentially Weighted Moving Averages (EWMA)\n",
    "            # EWMA places more weight on recent data → captures momentum and short-term trends better than simple averages.\n",
    "            add_cols.append(pl.col(col).ewm_mean(span=window_size, adjust=False).over('stock_id','date_id').alias(f\"rolling_ewm_{window_size}_{col}\"))\n",
    "            #feas_list.append(f\"rolling_ewm_{window_size}_{col}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            # Difference Between Fast and Slow EWMAs (e.g., 12-period minus 24-period) \n",
    "            # → this is the \"DIF\" signal in MACD which capture shifts in momentum\n",
    "            add_cols.append((pl.col(f\"rolling_ewm_{w1}_{col}\") - pl.col(f\"rolling_ewm_{w2}_{col}\")).alias(f\"dif_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"dif_{col}_{w1}_{w2}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            # Calculates an EWMA of the DIF line to create the MACD signal line (DEA)\n",
    "            # Smooths out short-term fluctuations in momentum to highlight clearer trend signals.\n",
    "            add_cols.append(pl.col(f\"dif_{col}_{w1}_{w2}\").ewm_mean(span=9, adjust=False).over('stock_id','date_id').alias(f\"dea_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"dea_{col}_{w1}_{w2}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            add_cols.append((pl.col(f\"dif_{col}_{w1}_{w2}\") - pl.col(f\"dea_{col}_{w1}_{w2}\")).alias(f\"macd_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"macd_{col}_{w1}_{w2}\")\n",
    "    \n",
    "    feas_list.extend(['macd_imb1_reference_price_wap_12_24',\n",
    " 'dif_imb1_reference_price_wap_3_6',\n",
    " 'macd_mid_price_near_far_12_24',\n",
    " 'dif_near_price_3_6',\n",
    " 'macd_near_price_24_48',\n",
    " 'dea_imb1_reference_price_wap_12_24',\n",
    " 'macd_near_price_12_24',\n",
    " 'rolling_ewm_24_imb1_reference_price_wap',\n",
    " 'dif_near_price_6_12',\n",
    " 'dea_mid_price_near_far_6_12',\n",
    " 'dea_near_price_24_48',\n",
    " 'rolling_ewm_12_imb1_reference_price_wap',\n",
    " 'dif_imb1_reference_price_wap_12_24'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in [\"target\"]:\n",
    "        # 176 1,2,3,5,10,15,20,25,30\n",
    "        # [1,2,3,5,10,15,20,25,30,35,40,45,60] 5.8704926 157\n",
    "        # [1,2,3,5,10,15,20,30,45,60] 5.8708683137\n",
    "        for window_size in [1,2,3,5,10,15,20,25,30,35,40,45,60]:\n",
    "            add_cols.append(pl.col(col).shift(1).rolling_mean(window_size=window_size,min_periods=1).over('stock_id','seconds_in_bucket').alias(f'rolling_mean_{window_size}_{col}_second'))\n",
    "            add_cols.append(pl.col(col).shift(1).rolling_std(window_size=window_size,min_periods=1).over('stock_id','seconds_in_bucket').alias(f'rolling_std_{window_size}_{col}_second'))\n",
    "            # Helps the model learn patterns from recent returns and volatility, capturing both short-term trends (e.g., 1–5 periods) and longer-term dynamics (e.g., 30–60 periods)\n",
    "            # Performed within each stock_id and seconds_in_bucket group, preserving the intraday structure and avoiding leakage across stocks or time buckets\n",
    "            \n",
    "            feas_list.extend([f'rolling_mean_{window_size}_{col}_second',f'rolling_std_{window_size}_{col}_second',])\n",
    "\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    return df.to_pandas(), feas_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2r/j5lhlppd6tqd8wf9zh69tb3c0000gn/T/ipykernel_24370/1496208167.py:112: DeprecationWarning: The argument `min_periods` for `Expr.rolling_mean` is deprecated. It has been renamed to `min_samples`.\n",
      "  add_cols.append(pl.col(col).rolling_mean(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_mean_{col}'))\n",
      "/var/folders/2r/j5lhlppd6tqd8wf9zh69tb3c0000gn/T/ipykernel_24370/1496208167.py:113: DeprecationWarning: The argument `min_periods` for `Expr.rolling_std` is deprecated. It has been renamed to `min_samples`.\n",
      "  add_cols.append(pl.col(col).rolling_std(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_std_{col}'))\n",
      "/var/folders/2r/j5lhlppd6tqd8wf9zh69tb3c0000gn/T/ipykernel_24370/1496208167.py:219: DeprecationWarning: The argument `min_periods` for `Expr.rolling_mean` is deprecated. It has been renamed to `min_samples`.\n",
      "  add_cols.append(pl.col(col).rolling_mean(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_mean_{col}'))\n",
      "/var/folders/2r/j5lhlppd6tqd8wf9zh69tb3c0000gn/T/ipykernel_24370/1496208167.py:334: DeprecationWarning: The argument `min_periods` for `Expr.rolling_mean` is deprecated. It has been renamed to `min_samples`.\n",
      "  add_cols.append(pl.col(col).shift(1).rolling_mean(window_size=window_size,min_periods=1).over('stock_id','seconds_in_bucket').alias(f'rolling_mean_{window_size}_{col}_second'))\n",
      "/var/folders/2r/j5lhlppd6tqd8wf9zh69tb3c0000gn/T/ipykernel_24370/1496208167.py:335: DeprecationWarning: The argument `min_periods` for `Expr.rolling_std` is deprecated. It has been renamed to `min_samples`.\n",
      "  add_cols.append(pl.col(col).shift(1).rolling_std(window_size=window_size,min_periods=1).over('stock_id','seconds_in_bucket').alias(f'rolling_std_{window_size}_{col}_second'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4236893, 157)\n"
     ]
    }
   ],
   "source": [
    "train_feas_all, feas_list = generate_features_no_hist_polars(train)\n",
    "valid_feas = train_feas_all[train_feas_all['date_id'] >= 390]\n",
    "train_feas = train_feas_all[train_feas_all['date_id'] < 390]\n",
    "# train_feas = train_feas[train_feas['fold']==0]\n",
    "\n",
    "#4,236,893 rows (observations) and 157 columns (features)\n",
    "print(train_feas[feas_list].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_feas = train_feas.fillna(-9e10)\n",
    "valid_feas = valid_feas.fillna(-9e10)\n",
    "from tqdm.auto import tqdm\n",
    "for _ in tqdm(feas_list):\n",
    "    train_feas[_] = train_feas[_].clip(lower=-9e9,upper=9e9)\n",
    "    valid_feas[_] = valid_feas[_].clip(lower=-9e9,upper=9e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [17:13:54] WARNING: /Users/runner/work/xgboost/xgboost/src/context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:6.02907\n",
      "[200]\tvalidation_0-mae:5.91408\n",
      "[400]\tvalidation_0-mae:5.89466\n",
      "[600]\tvalidation_0-mae:5.88516\n",
      "[800]\tvalidation_0-mae:5.88006\n",
      "[1000]\tvalidation_0-mae:5.87699\n",
      "[1200]\tvalidation_0-mae:5.87504\n",
      "[1400]\tvalidation_0-mae:5.87367\n",
      "[1600]\tvalidation_0-mae:5.87271\n",
      "[1800]\tvalidation_0-mae:5.87215\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      1\u001b[39m params = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m47\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0.01\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mgamma\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.24378704040107024\u001b[39m\n\u001b[32m     15\u001b[39m }\n\u001b[32m     17\u001b[39m clf = xgb.XGBRegressor(**params)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_feas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeas_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_feas\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_feas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeas_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_feas\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'random_state': 47,\n",
    "    'learning_rate':0.01,\n",
    "    'n_estimators':10000,\n",
    "    'n_jobs':-1,\n",
    "    'objective':'reg:absoluteerror',\n",
    "    \"device\": \"gpu\",\n",
    "    'max_depth': 10,\n",
    "     'min_child_weight': 8.860379669551103,\n",
    "     'subsample': 0.7711820080525443,\n",
    "     'colsample_bytree': 0.5348780216605801,\n",
    "     'reg_alpha': 0.12854342791716195,\n",
    "     'reg_lambda': 0.39326076062073634,\n",
    "     'gamma': 0.24378704040107024\n",
    "}\n",
    "\n",
    "clf = xgb.XGBRegressor(**params)\n",
    "\n",
    "clf.fit(\n",
    "    train_feas[feas_list], train_feas['target'],\n",
    "    eval_set=[(valid_feas[feas_list], valid_feas['target'])],\n",
    "    verbose=200\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
